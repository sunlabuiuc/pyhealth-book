{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:18:19.230768Z",
     "start_time": "2024-02-29T05:18:14.813891Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Define the Attention Mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:26:23.106123Z",
     "start_time": "2024-02-29T05:26:23.101104Z"
    }
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        d_k = query.size(-1)  # Dimension of the key, used for scaling down the dot product\n",
    "        # Calculate the dot products of the query with all keys, divide each by sqrt(d_k),\n",
    "        # and apply a softmax to obtain the weights on the values\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            # Apply mask - set scores to -inf where mask is 0 to ignore these positions\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        p_attn = torch.softmax(scores, dim=-1)  # Softmax to obtain the weights\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)  # Apply dropout to the attention weights\n",
    "        # Multiply the weights by the value to get the output\n",
    "        return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:28:12.612469Z",
     "start_time": "2024-02-29T05:28:12.608025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 5, 512])\n",
      "Attention Weights shape: torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example \"\"\"\n",
    "# Assuming dimensions for simplicity: batch_size=1, seq_len=5, model_dim=512\n",
    "query = key = value = torch.rand(1, 5, 512)\n",
    "attention_module = Attention()\n",
    "output, attn_weights = attention_module(query, key, value)\n",
    "print(\"Output shape:\", output.shape)  # Expected shape: (1, 5, 512)\n",
    "print(\"Attention Weights shape:\", attn_weights.shape)  # Expected shape: (1, 5, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Multi-Headed Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:26:32.114536Z",
     "start_time": "2024-02-29T05:26:32.107437Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_k = d_model // h  # Dimension of each head\n",
    "        self.h = h  # Number of heads\n",
    "        # Linear layers for projecting Q, K, V\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
    "        self.output_linear = nn.Linear(d_model, d_model)  # Final projection\n",
    "        self.attention = Attention()  # The attention mechanism defined above\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "        # Prepare Q, K, V for multi-head processing (split into h heads)\n",
    "        query, key, value = \\\n",
    "            [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linear_layers, (query, key, value))]\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1)  # Adjust mask for multi-heads\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "        return self.output_linear(x)  # Apply final linear projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:30:00.820486Z",
     "start_time": "2024-02-29T05:30:00.807213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Headed Attention Output shape: torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example \"\"\"\n",
    "query = key = value = torch.rand(1, 10, 512)  # Example dimensions: batch_size=1, seq_len=10, d_model=512\n",
    "multi_head_attention = MultiHeadedAttention(h=8, d_model=512)\n",
    "output = multi_head_attention(query, key, value)\n",
    "print(\"Multi-Headed Attention Output shape:\", output.shape)  # Expected shape: (1, 10, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Position-wise Feed-forward Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:26:44.010431Z",
     "start_time": "2024-02-29T05:26:44.006473Z"
    }
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(d_model, d_ff)  # First linear transformation\n",
    "        self.l2 = nn.Linear(d_ff, d_model)  # Second linear transformation\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout for regularization\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.l2(self.dropout(nn.ReLU()(self.l1(x))))  # Apply ReLU between the linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:30:14.911666Z",
     "start_time": "2024-02-29T05:30:14.887916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feed-forward Network Output shape: torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example \"\"\"\n",
    "input_tensor = torch.rand(1, 10, 512)  # Example dimensions: batch_size=1, seq_len=10, d_model=512\n",
    "ffn = PositionwiseFeedForward(d_model=512, d_ff=2048)\n",
    "ffn_output = ffn(input_tensor)\n",
    "print(\"Feed-forward Network Output shape:\", ffn_output.shape)  # Expected shape: (1, 10, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Sublayer Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:26:48.776459Z",
     "start_time": "2024-02-29T05:26:48.772735Z"
    }
   },
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(size)  # Normalize the input\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        # Apply normalization, sublayer operation, and dropout, then add the input x for residual connection\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:30:25.124068Z",
     "start_time": "2024-02-29T05:30:25.119348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sublayer Connection Output shape: torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example \"\"\"\n",
    "input_tensor = torch.rand(1, 10, 512)  # Example dimensions: batch_size=1, seq_len=10, d_model=512\n",
    "sublayer_connection = SublayerConnection(size=512, dropout=0.1)\n",
    "# Example sublayer function: Let's use a lambda that adds a constant tensor for simplicity\n",
    "sublayer_output = sublayer_connection(input_tensor, lambda x: x + torch.ones_like(x))\n",
    "print(\"Sublayer Connection Output shape:\", sublayer_output.shape)  # Expected shape: (1, 10, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Transformer Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:27:10.952710Z",
     "start_time": "2024-02-29T05:27:10.947451Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden, attn_heads, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadedAttention(h=attn_heads, d_model=hidden, dropout=dropout)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=4 * hidden, dropout=dropout)\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # Apply attention to the input\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention(_x, _x, _x, mask=mask))\n",
    "        # Apply feed-forward network to the result\n",
    "        x = self.output_sublayer(x, self.feed_forward)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:30:34.725231Z",
     "start_time": "2024-02-29T05:30:34.688176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer Block Output shape: torch.Size([1, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Example \"\"\"\n",
    "input_tensor = torch.rand(1, 10, 512)  # Example dimensions: batch_size=1, seq_len=10, d_model=512\n",
    "transformer_block = TransformerBlock(hidden=512, attn_heads=8, dropout=0.1)\n",
    "transformer_output = transformer_block(input_tensor)\n",
    "print(\"Transformer Block Output shape:\", transformer_output.shape)  # Expected shape: (1, 10, 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-29T05:27:11.609060Z",
     "start_time": "2024-02-29T05:27:11.571474Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor shape: torch.Size([5, 10, 512])\n",
      "mask shape: torch.Size([5, 10, 10])\n",
      "output shape: torch.Size([5, 10, 512])\n"
     ]
    }
   ],
   "source": [
    "# Example input\n",
    "batch_size = 5\n",
    "seq_length = 10\n",
    "hidden = 512\n",
    "model = TransformerBlock(hidden=hidden, attn_heads=8, dropout=0.1)\n",
    "input_tensor = torch.rand(batch_size, seq_length, hidden)\n",
    "\n",
    "# Example mask (optional)\n",
    "mask = torch.randint(0, 2, (batch_size, seq_length))\n",
    "mask = torch.einsum(\"ab,ac->abc\", mask, mask)\n",
    "\n",
    "# Forward pass\n",
    "print(\"input_tensor shape:\", input_tensor.shape)\n",
    "print(\"mask shape:\", mask.shape)\n",
    "output = model(input_tensor, mask=mask)\n",
    "print(\"output shape:\", output.shape)  # Expected shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch19",
   "language": "python",
   "name": "pytorch19"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
